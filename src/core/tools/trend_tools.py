# src/mcp/tools/trend_tools.py
from typing import Dict, Any, List
import structlog
from mcp.types import Tool, TextContent

from .base_tools import BaseTools
from src.utils.error_handler import handle_tool_error

logger = structlog.get_logger()

class TrendTools(BaseTools):
    """è¶‹åŠ¿åˆ†æå·¥å…· - MVPç‰ˆæœ¬"""
    
    def get_tools(self) -> List[Tool]:
        """è·å–å·¥å…·å®šä¹‰"""
        return [
            Tool(
                name="get_trending_papers",
                description="è·å–çƒ­é—¨è®ºæ–‡è¶‹åŠ¿",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "time_window": {
                            "type": "string",
                            "enum": ["week", "month", "year"],
                            "default": "month",
                            "description": "æ—¶é—´çª—å£"
                        },
                        "limit": {
                            "type": "integer",
                            "minimum": 1,
                            "maximum": 50,
                            "default": 20,
                            "description": "è¿”å›ç»“æœæ•°é‡"
                        }
                    }
                }
            ),
            Tool(
                name="get_top_keywords",
                description="è·å–çƒ­é—¨ç ”ç©¶è¯é¢˜",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "limit": {
                            "type": "integer",
                            "minimum": 1,
                            "maximum": 100,
                            "default": 20,
                            "description": "è¿”å›å…³é”®è¯æ•°é‡"
                        }
                    }
                }
            )
        ]
    
    @handle_tool_error
    async def get_trending_papers(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """è·å–çƒ­é—¨è®ºæ–‡å·¥å…·"""
        time_window = arguments.get("time_window", "month")
        limit = arguments.get("limit", 20)
        
        logger.info("Getting trending papers", time_window=time_window, limit=limit)
        
        try:
            raw_result = await self.go_client.get_trending_papers(
                time_window=time_window,
                limit=limit
            )
            
            content = self._format_trending_papers(raw_result, time_window)
            return [TextContent(type="text", text=content)]
            
        except Exception as e:
            logger.error("Get trending papers failed", error=str(e))
            error_content = self._format_error_response(str(e), "è·å–çƒ­é—¨è®ºæ–‡")
            return [TextContent(type="text", text=error_content)]
    
    @handle_tool_error
    async def get_top_keywords(self, arguments: Dict[str, Any]) -> List[TextContent]:
        """è·å–çƒ­é—¨å…³é”®è¯å·¥å…·"""
        limit = arguments.get("limit", 20)
        
        logger.info("Getting top keywords", limit=limit)
        
        try:
            raw_result = await self.go_client.get_top_keywords()
            
            content = self._format_top_keywords(raw_result, limit)
            return [TextContent(type="text", text=content)]
            
        except Exception as e:
            logger.error("Get top keywords failed", error=str(e))
            error_content = self._format_error_response(str(e), "è·å–çƒ­é—¨å…³é”®è¯")
            return [TextContent(type="text", text=error_content)]
    
    def _format_trending_papers(self, raw_result: Dict[str, Any], time_window: str) -> str:
        """æ ¼å¼åŒ–çƒ­é—¨è®ºæ–‡ç»“æœ"""
        papers = raw_result.get("trending_papers", [])
        count = raw_result.get("count", len(papers))
        
        time_window_cn = {
            "week": "æœ¬å‘¨",
            "month": "æœ¬æœˆ", 
            "year": "æœ¬å¹´"
        }.get(time_window, time_window)
        
        content = f"# {time_window_cn}çƒ­é—¨è®ºæ–‡\n\n"
        content += f"**æ—¶é—´èŒƒå›´**: {time_window_cn}\n"
        content += f"**è®ºæ–‡æ•°é‡**: {count}\n\n"
        
        if not papers:
            content += f"{time_window_cn}æš‚æ— çƒ­é—¨è®ºæ–‡æ•°æ®ã€‚\n"
            return content
        
        content += f"## çƒ­é—¨è®ºæ–‡æ’è¡Œæ¦œ\n\n"
        
        for i, paper in enumerate(papers, 1):
            title = self._safe_get_str(paper, 'title', 'Unknown Title')
            content += f"### {i}. {title}\n\n"
            
            # åŸºæœ¬ä¿¡æ¯
            content += self._format_paper_basic_info(paper)
            
            # çƒ­åº¦æŒ‡æ ‡
            popularity_score = paper.get('popularity_score')
            if popularity_score is not None:
                content += f"**çƒ­åº¦è¯„åˆ†**: {popularity_score:.2f}\n"
            
            # æ‘˜è¦
            abstract = self._safe_get_str(paper, 'abstract')
            if abstract:
                content += f"**æ‘˜è¦**: {self._truncate_text(abstract, 150)}\n"
            
            # å…³é”®è¯
            keywords = paper.get('keywords', [])
            if keywords:
                content += f"**å…³é”®è¯**: {self._format_keywords(keywords, max_count=5)}\n"
            
            # è®ºæ–‡ID
            content += f"**ID**: {self._safe_get_str(paper, 'id', 'N/A')}\n"
            content += "\n---\n\n"
        
        return content
    
    def _format_top_keywords(self, raw_result: Dict[str, Any], limit: int) -> str:
        """æ ¼å¼åŒ–çƒ­é—¨å…³é”®è¯ç»“æœ"""
        keywords = raw_result.get("keywords", [])
        count = raw_result.get("count", len(keywords))
        
        content = f"# çƒ­é—¨ç ”ç©¶è¯é¢˜\n\n"
        content += f"**å…³é”®è¯æ€»æ•°**: {count}\n"
        content += f"**æ˜¾ç¤ºæ•°é‡**: {min(limit, len(keywords))}\n\n"
        
        if not keywords:
            content += "æš‚æ— çƒ­é—¨å…³é”®è¯æ•°æ®ã€‚\n"
            return content
        
        content += f"## çƒ­é—¨è¯é¢˜æ’è¡Œæ¦œ\n\n"
        
        # é™åˆ¶æ˜¾ç¤ºæ•°é‡
        display_keywords = keywords[:limit]
        
        for i, keyword_data in enumerate(display_keywords, 1):
            keyword = self._safe_get_str(keyword_data, 'keyword', 'Unknown')
            paper_count = self._safe_get_int(keyword_data, 'paper_count')
            
            content += f"{i}. **{keyword}**"
            if paper_count > 0:
                content += f" ({paper_count} ç¯‡è®ºæ–‡)"
            
            # æ·»åŠ çƒ­åº¦æŒ‡ç¤ºå™¨
            if i <= 3:
                content += " ğŸ”¥"
            elif i <= 10:
                content += " ğŸ“ˆ"
            
            content += "\n"
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        if len(display_keywords) >= 5:
            total_papers = sum(
                self._safe_get_int(kw, 'paper_count') 
                for kw in display_keywords[:5]
            )
            content += f"\n## ç»Ÿè®¡ä¿¡æ¯\n"
            content += f"- å‰5ä¸ªçƒ­é—¨è¯é¢˜å…±æ¶‰åŠ {total_papers} ç¯‡è®ºæ–‡\n"
            
            # è®¡ç®—å¹³å‡è®ºæ–‡æ•°
            if len(display_keywords) > 0:
                avg_papers = sum(
                    self._safe_get_int(kw, 'paper_count') 
                    for kw in display_keywords
                ) / len(display_keywords)
                content += f"- å¹³å‡æ¯ä¸ªè¯é¢˜æ¶‰åŠ {avg_papers:.1f} ç¯‡è®ºæ–‡\n"
        
        return content